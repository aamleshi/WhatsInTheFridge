{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensornets as nets\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17910545177437239935\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 10367977521282374813\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 15515218579992382361\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(path, batchsize = 16):\n",
    "    try:\n",
    "        labels = np.load(\"batchedData/\"+path+\"/labels\")\n",
    "    except:\n",
    "        print(\"No labels found\", \"batchedData\"+path+\"/labels\")\n",
    "        return 0\n",
    "    try:\n",
    "        features = []\n",
    "        i = 0\n",
    "        while True:\n",
    "            features.append(np.load(\"batchedData\"+path+'/'+str(i)))\n",
    "            i = i+1\n",
    "    except:\n",
    "        return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No labels found batchedDatapreprocess_validation.p/labels\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-803b084943ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalid_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'preprocess_validation.p'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "valid_features, valid_labels = getData('preprocess_validation.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=(None, 224, 224, 3), name='input_x')\n",
    "y = tf.placeholder(tf.float32, shape=(None, 5), name='output_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HYPER-PARAMETERS\n",
    "learning_rate = 0.00001\n",
    "epochs = 6\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = nets.VGG19(x, is_training=True, classes=5)\n",
    "model = tf.identity(logits,name='logits')\n",
    "loss = tf.losses.softmax_cross_entropy(y,logits)\n",
    "train = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(model,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scope: vgg19\n",
      "conv1/1/conv/BiasAdd:0 (?, 224, 224, 64)\n",
      "conv1/1/Relu:0 (?, 224, 224, 64)\n",
      "conv1/2/conv/BiasAdd:0 (?, 224, 224, 64)\n",
      "conv1/2/Relu:0 (?, 224, 224, 64)\n",
      "conv1/pool/MaxPool:0 (?, 112, 112, 64)\n",
      "conv2/1/conv/BiasAdd:0 (?, 112, 112, 128)\n",
      "conv2/1/Relu:0 (?, 112, 112, 128)\n",
      "conv2/2/conv/BiasAdd:0 (?, 112, 112, 128)\n",
      "conv2/2/Relu:0 (?, 112, 112, 128)\n",
      "conv2/pool/MaxPool:0 (?, 56, 56, 128)\n",
      "conv3/1/conv/BiasAdd:0 (?, 56, 56, 256)\n",
      "conv3/1/Relu:0 (?, 56, 56, 256)\n",
      "conv3/2/conv/BiasAdd:0 (?, 56, 56, 256)\n",
      "conv3/2/Relu:0 (?, 56, 56, 256)\n",
      "conv3/3/conv/BiasAdd:0 (?, 56, 56, 256)\n",
      "conv3/3/Relu:0 (?, 56, 56, 256)\n",
      "conv3/4/conv/BiasAdd:0 (?, 56, 56, 256)\n",
      "conv3/4/Relu:0 (?, 56, 56, 256)\n",
      "conv3/pool/MaxPool:0 (?, 28, 28, 256)\n",
      "conv4/1/conv/BiasAdd:0 (?, 28, 28, 512)\n",
      "conv4/1/Relu:0 (?, 28, 28, 512)\n",
      "conv4/2/conv/BiasAdd:0 (?, 28, 28, 512)\n",
      "conv4/2/Relu:0 (?, 28, 28, 512)\n",
      "conv4/3/conv/BiasAdd:0 (?, 28, 28, 512)\n",
      "conv4/3/Relu:0 (?, 28, 28, 512)\n",
      "conv4/4/conv/BiasAdd:0 (?, 28, 28, 512)\n",
      "conv4/4/Relu:0 (?, 28, 28, 512)\n",
      "conv4/pool/MaxPool:0 (?, 14, 14, 512)\n",
      "conv5/1/conv/BiasAdd:0 (?, 14, 14, 512)\n",
      "conv5/1/Relu:0 (?, 14, 14, 512)\n",
      "conv5/2/conv/BiasAdd:0 (?, 14, 14, 512)\n",
      "conv5/2/Relu:0 (?, 14, 14, 512)\n",
      "conv5/3/conv/BiasAdd:0 (?, 14, 14, 512)\n",
      "conv5/3/Relu:0 (?, 14, 14, 512)\n",
      "conv5/4/conv/BiasAdd:0 (?, 14, 14, 512)\n",
      "conv5/4/Relu:0 (?, 14, 14, 512)\n",
      "conv5/pool/MaxPool:0 (?, 7, 7, 512)\n",
      "flatten/flatten/Reshape:0 (?, 25088)\n",
      "fc6/BiasAdd:0 (?, 4096)\n",
      "relu6:0 (?, 4096)\n",
      "drop6/dropout/mul:0 (?, 4096)\n",
      "fc7/BiasAdd:0 (?, 4096)\n",
      "relu7:0 (?, 4096)\n",
      "drop7/dropout/mul:0 (?, 4096)\n",
      "logits/BiasAdd:0 (?, 5)\n",
      "probs:0 (?, 5)\n"
     ]
    }
   ],
   "source": [
    "logits.print_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scope: vgg19\n",
      "Total layers: 19\n",
      "Total weights: 114\n",
      "Total parameters: 418,772,175\n"
     ]
    }
   ],
   "source": [
    "logits.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_features_labels(features, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Split features and labels into batches\n",
    "    \"\"\"\n",
    "    for start in range(0, len(features), batch_size):\n",
    "        end = min(start + batch_size, len(features))\n",
    "        yield features[start:end], labels[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocess_training_batch(batch_id, batch_size):\n",
    "    \"\"\"\n",
    "    Load the Preprocessed Training data and return them in batches of <batch_size> or less\n",
    "    \"\"\"\n",
    "    filename = 'preprocess_batch_' + str(batch_id) + '.p'\n",
    "    features, labels = getData(filename)\n",
    "\n",
    "    # Return the training data in batches of size <batch_size> or less\n",
    "    return batch_features_labels(features, labels, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "global_variables_initializer ... done ...\n",
      "model.pretrained ... done ... \n",
      "starting training ... \n",
      "Epoch  1, Batch 1:  "
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1e32918d9020>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mtmp_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Validation Accuracy: {:.6f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_acc\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtmp_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Save Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:    \n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('global_variables_initializer ... done ...')\n",
    "    sess.run(logits.pretrained())\n",
    "    print('model.pretrained ... done ... ')    \n",
    "    \n",
    "    # Training cycle\n",
    "    print('starting training ... ')\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 4\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in load_preprocess_training_batch(batch_i, batch_size):\n",
    "                sess.run(train, {x: batch_features, y: batch_labels})\n",
    "                \n",
    "            print('Epoch {:>2}, Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            \n",
    "            # calculate the mean accuracy over all validation dataset\n",
    "            valid_acc = 0\n",
    "            for batch_valid_features, batch_valid_labels in batch_features_labels(valid_features, valid_labels, batch_size):\n",
    "                valid_acc += sess.run(accuracy, {x:batch_valid_features, y:batch_valid_labels})\n",
    "            \n",
    "            tmp_num = len(valid_features)/batch_size\n",
    "            print('Validation Accuracy: {:.6f}'.format(valid_acc/tmp_num))\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
