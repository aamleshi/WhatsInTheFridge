{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensornets as nets\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation Guide:  \n",
    "- [X] Read In Images  \n",
    "- [ ] Create Labels\n",
    "- [ ] Split data into training and validation- \n",
    "- [ ] Load in Model\n",
    "- [ ] Change last layer of model\n",
    "- [ ] Manipulate images to fit model\n",
    "- [ ] Train Model with new data\n",
    "- [ ] Validate Perfomance\n",
    "- [ ] Save Model\n",
    "- [ ] Write function to classify 1 image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Images From File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a8f00ddb2f94241b88e47c72dcbde3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a90e741a794f1da7b2c42cbe34cd41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=56), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2decf615ef347fb83d0ce478aefa8e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=56), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd976b0358b45f7b09843ebd34373cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=56), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80df1bf28ac94b2388ea842f0074f39d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa0f637aa5cc49448d45d5289645d073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=56), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = [\"Can\", \"Cookies\", \"Eggs\", \"Empty\", \"Fruit\"]\n",
    "dataDict = {classID: [] for classID in classes}\n",
    "img_dir = \"./Classes/\"\n",
    "for classID in tqdm_notebook(classes):\n",
    "    path = img_dir + classID\n",
    "    images = os.listdir(path)\n",
    "    #print(len(images), classID)\n",
    "    for image in tqdm_notebook(images):\n",
    "        pic = Image.open(os.path.join(path,image))\n",
    "        pix = np.array(pic.getdata()).reshape(pic.size[0], pic.size[1], 3)\n",
    "        dataDict[classID] = dataDict[classID] + [pix]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into train and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(classes):\n",
    "    encoded = np.zeros((len(x), 5))\n",
    "    \n",
    "    for idx, val in enumerate(x):\n",
    "        encoded[idx][val] = 1\n",
    "        \n",
    "    return encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 26613.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 29\n",
      "240 240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train_validate_split(validfrac = .1):\n",
    "    valid_features = []\n",
    "    valid_labels = []\n",
    "    train_features = []\n",
    "    train_labels = []\n",
    "    for classID in tqdm(classes):\n",
    "        num_images = len(dataDict[classID])\n",
    "        validIdx = math.ceil(num_images*validfrac)\n",
    "        valid_features.extend(dataDict[classID][:validIdx])\n",
    "        valid_labels.extend([classID]*validIdx)\n",
    "        train_features.extend(dataDict[classID][validIdx:])\n",
    "        train_labels.extend([classID]*(num_images-validIdx))\n",
    "    return (valid_features, valid_labels, train_features, train_labels)\n",
    "\n",
    "(valid_features, valid_labels, train_features, train_labels) = train_validate_split()\n",
    "print(len(valid_features), len(valid_labels))\n",
    "print(len(train_features), len(train_labels))\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INPUT and OUTPUT tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=(None, 224, 224, 3), name='input_x')\n",
    "y = tf.placeholder(tf.float32, shape=(None, 10), name='output_y')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HYPER-PARAMETERS\n",
    "learning_rate = 0.00001\n",
    "epochs = 16\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = nets.VGG19(x, is_training=True, classes=5)\n",
    "model = tf.identity(logits,name='logits')\n",
    "loss = tf.losses.softmax_cross_entropy(y,logits)\n",
    "train = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(model,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits.print_outputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "https://github.com/deep-diver/CIFAR10-VGG19-Tensorflow/blob/master/CIFAR10-transfer-learning-tensornets.ipynb  \n",
    "https://towardsdatascience.com/transfer-learning-in-tensorflow-9e4f7eae3bb4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
