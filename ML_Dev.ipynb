{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensornets as nets\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import pickle\n",
    "import math\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation Guide:  \n",
    "- [X] Read In Images  \n",
    "- [ ] Create Labels\n",
    "- [ ] Split data into training and validation- \n",
    "- [ ] Load in Model\n",
    "- [ ] Change last layer of model\n",
    "- [ ] Manipulate images to fit model\n",
    "- [ ] Train Model with new data\n",
    "- [ ] Validate Perfomance\n",
    "- [ ] Save Model\n",
    "- [ ] Write function to classify 1 image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Images From File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09168fb5de1c4358a93aa0978793a6f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b7a8c55034d4c79ba2357ec83bbe8bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=166), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eacec3c6c054577830405214ecef37e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=166), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = [\"Can\", \"Cookies\", \"Eggs\", \"Empty\", \"Fruit\"]\n",
    "dataDict = {classID: [] for classID in classes}\n",
    "img_dir = \"./Classes/\"\n",
    "for classID in tqdm_notebook(classes):\n",
    "    path = img_dir + classID\n",
    "    images = os.listdir(path)\n",
    "    #print(len(images), classID)\n",
    "    for image in tqdm_notebook(images):\n",
    "        pic = Image.open(os.path.join(path,image))\n",
    "        pix = np.array(pic.getdata()).reshape(pic.size[1], pic.size[0], 3)\n",
    "        dataDict[classID] = dataDict[classID] + [pix]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into train and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(x):\n",
    "    classEncoder = {classID:i for (i, classID) in enumerate(classes)}\n",
    "    encoded = np.zeros((len(x), 5))\n",
    "    \n",
    "    for idx, val in enumerate(x):\n",
    "        encoded[idx][classEncoder[val]] = 1\n",
    "        \n",
    "    return encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_split(validfrac = .1):\n",
    "    valid_features = []\n",
    "    valid_labels = []\n",
    "    train_features = []\n",
    "    train_labels = []\n",
    "    for classID in tqdm(classes):\n",
    "        num_images = len(dataDict[classID])\n",
    "        validIdx = math.ceil(num_images*validfrac)\n",
    "        valid_features.extend(dataDict[classID][:validIdx])\n",
    "        valid_labels.extend([classID]*validIdx)\n",
    "        train_features.extend(dataDict[classID][validIdx:])\n",
    "        train_labels.extend([classID]*(num_images-validIdx))\n",
    "    return (valid_features, valid_labels, train_features, train_labels)\n",
    "\n",
    "(valid_features, valid_labels, train_features, train_labels) = train_validate_split()\n",
    "one_hot_valid = one_hot_encode(valid_labels)\n",
    "one_hot_train = one_hot_encode(train_labels)\n",
    "print(len(valid_features), len(valid_labels))\n",
    "print(len(train_features), len(train_labels))\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_and_save(features, labels, filename):\n",
    "    labels = one_hot_encode(labels)\n",
    "\n",
    "    pickle.dump((features, labels), open(filename, 'wb'))\n",
    "\n",
    "\n",
    "def preprocess_and_save_data():\n",
    "    n_batches = 23\n",
    "    batchPath = \"batchedImages/\"\n",
    "    (valid_features, valid_labels, train_features, train_labels) = train_validate_split()\n",
    "    \n",
    "    batchLen = math.floor(len(valid_features)/n_batches)\n",
    "    for batch_i in range(1, n_batches + 1):\n",
    "        features = train_features[(batch_i-1)*batchLen:(batch_i*batchLen)]\n",
    "        labels = train_labels[(batch_i-1)*batchLen:(batch_i*batchLen)]\n",
    "        \n",
    "        # find index to be the point as validation data in the whole dataset of the batch (10%)\n",
    "\n",
    "        # preprocess the 90% of the whole dataset of the batch\n",
    "        # - normalize the features\n",
    "        # - one_hot_encode the lables\n",
    "        # - save in a new file named, \"preprocess_batch_\" + batch_number\n",
    "        # - each file for each batch\n",
    "        _preprocess_and_save(features, labels, \n",
    "                             batchPath+'preprocess_batch_' + str(batch_i) + '.p')\n",
    "    _preprocess_and_save(np.array(valid_features), np.array(valid_labels),\n",
    "                         batchPath+'preprocess_validation.p')\n",
    "    _preprocess_and_save(np.array(valid_features), np.array(valid_labels),\n",
    "                         batchPath+'preprocess_testing.p')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_and_save_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INPUT and OUTPUT tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=(None, 224, 224, 3), name='input_x')\n",
    "y = tf.placeholder(tf.float32, shape=(None, 5), name='output_y')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HYPER-PARAMETERS\n",
    "learning_rate = 0.00001\n",
    "epochs = 16\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = nets.VGG19(x, is_training=True, classes=5)\n",
    "model = tf.identity(logits,name='logits')\n",
    "loss = tf.losses.softmax_cross_entropy(y,logits)\n",
    "train = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(model,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits.print_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_features_labels(features, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Split features and labels into batches\n",
    "    \"\"\"\n",
    "    for start in range(0, len(features), batch_size):\n",
    "        end = min(start + batch_size, len(features))\n",
    "        yield features[start:end], labels[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocess_training_batch(batch_id, batch_size):\n",
    "    \"\"\"\n",
    "    Load the Preprocessed Training data and return them in batches of <batch_size> or less\n",
    "    \"\"\"\n",
    "    batchPath = \"batchedImages/\"\n",
    "    filename = batchPath+'preprocess_batch_' + str(batch_id) + '.p'\n",
    "    features, labels = pickle.load(open(filename, mode='rb'))\n",
    "    \n",
    "    tmpFeatures = []\n",
    "    \n",
    "    for feature in features:\n",
    "        feature = np.copy(feature).astype('float')\n",
    "        tmpFeature = skimage.transform.resize(feature, (224, 224))\n",
    "        tmpFeature = np.copy(tmpFeature).astype('uint8')        \n",
    "        tmpFeatures.append(tmpFeature)\n",
    "\n",
    "    # Return the training data in batches of size <batch_size> or less\n",
    "    return batch_features_labels(tmpFeatures, labels, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpValidFeatures = []\n",
    "\n",
    "for feature in valid_features:\n",
    "    feature = np.copy(feature).astype('float')\n",
    "    tmpValidFeature = skimage.transform.resize(feature, (224, 224))\n",
    "    tmpValidFeature = np.copy(tmpValidFeature).astype('uint8')\n",
    "    tmpValidFeatures.append(tmpValidFeature)\n",
    "    \n",
    "tmpValidFeatures = np.array(tmpValidFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmpValidFeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:    \n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('global_variables_initializer ... done ...')\n",
    "    sess.run(logits.pretrained())\n",
    "    print('model.pretrained ... done ... ')    \n",
    "    \n",
    "    # Training cycle\n",
    "    print('starting training ... ')\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in load_preprocess_training_batch(batch_i, batch_size):\n",
    "                sess.run(train, {x: batch_features, y: batch_labels})\n",
    "                \n",
    "            print('Epoch {:>2}, Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            \n",
    "            # calculate the mean accuracy over all validation dataset\n",
    "            valid_acc = 0\n",
    "            for batch_valid_features, batch_valid_labels in batch_features_labels(tmpValidFeatures, valid_labels, batch_size):\n",
    "                valid_acc += sess.run(accuracy, {x:batch_valid_features, y:batch_valid_labels})\n",
    "            \n",
    "            tmp_num = tmpValidFeatures.shape[0]/batch_size\n",
    "            print('Validation Accuracy: {:.6f}'.format(valid_acc/tmp_num))\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label_names():\n",
    "    return classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def display_image_predictions(features, labels, predictions):\n",
    "    n_classes = 5\n",
    "    label_names = load_label_names()\n",
    "    label_binarizer = LabelBinarizer()\n",
    "    label_binarizer.fit(range(n_classes))\n",
    "    label_ids = label_binarizer.inverse_transform(np.array(labels))\n",
    "\n",
    "    fig, axs = plt.subplots(10, 2, figsize=(12,24))\n",
    "\n",
    "    margin = 0.05\n",
    "    ind = np.arange(n_classes)\n",
    "    width = (1. - 2. * margin) / n_classes    \n",
    "    \n",
    "    for image_i, (feature, label_id, prediction) in enumerate(zip(features, label_ids, predictions)):\n",
    "        correct_name = label_names[label_id]\n",
    "        pred_name = label_names[np.argmax(prediction)]\n",
    "        \n",
    "        is_match = 'False'        \n",
    "        \n",
    "        if np.argmax(prediction) == label_id:\n",
    "            is_match = 'True'\n",
    "            \n",
    "        predictions_array = []\n",
    "        pred_names = []\n",
    "        \n",
    "        for index, pred_value in enumerate(prediction):\n",
    "            tmp_pred_name = label_names[index]\n",
    "            predictions_array.append({tmp_pred_name : pred_value})\n",
    "            pred_names.append(tmp_pred_name)\n",
    "        \n",
    "        print('[{}] ground truth: {}, predicted result: {} | {}'.format(image_i, correct_name, pred_name, is_match))\n",
    "        print('\\t- {}\\n'.format(predictions_array))\n",
    "        \n",
    "#         print('image_i: ', image_i)\n",
    "#         print('axs: ', axs, ', axs len: ', len(axs))\n",
    "        axs[image_i][0].imshow(feature)\n",
    "        axs[image_i][0].set_title(pred_name)\n",
    "        axs[image_i][0].set_axis_off()\n",
    "        \n",
    "        axs[image_i][1].barh(ind + margin, prediction, width)\n",
    "        axs[image_i][1].set_yticks(ind + margin)\n",
    "        axs[image_i][1].set_yticklabels(pred_names)\n",
    "        \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features, test_labels = pickle.load(open('preprocess_testing.p', mode='rb'))\n",
    "tmpFeatures = []\n",
    "\n",
    "for feature in test_features:\n",
    "    feature = np.copy(feature).astype('float')\n",
    "    tmpFeature = skimage.transform.resize(feature, (224, 224))\n",
    "    tmpFeature = np.copy(tmpFeature).astype('uint8')\n",
    "    tmpFeatures.append(tmpFeature)\n",
    "\n",
    "tmpFeatures = np.asarray(tmpFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import random\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "batch_size = 64\n",
    "n_samples = 10\n",
    "top_n_predictions = 5\n",
    "\n",
    "def test_model(tmpFeatures):\n",
    "    loaded_graph = tf.Graph()\n",
    "    \n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        loaded_x = loaded_graph.get_tensor_by_name('input_x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('output_y:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in batch_features_labels(tmpFeatures, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        \n",
    "        tmpTestFeatures = []\n",
    "    \n",
    "        for feature in random_test_features:\n",
    "            feature = np.copy(feature).astype('float')\n",
    "            tmpTestFeature = skimage.transform.resize(feature, (224, 224))\n",
    "            tmpTestFeature = np.copy(tmpTestFeature).astype('uint8')            \n",
    "            tmpTestFeatures.append(tmpTestFeature)\n",
    "           \n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.softmax(loaded_logits),\n",
    "            feed_dict={loaded_x: tmpTestFeatures, loaded_y: random_test_labels})\n",
    "        \n",
    "        display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "test_model(tmpFeatures)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "https://github.com/deep-diver/CIFAR10-VGG19-Tensorflow/blob/master/CIFAR10-transfer-learning-tensornets.ipynb  \n",
    "https://towardsdatascience.com/transfer-learning-in-tensorflow-9e4f7eae3bb4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
